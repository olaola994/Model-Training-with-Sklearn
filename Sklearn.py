# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j709TNffk3AW_Y1-_vXTGD2RGyqohBAP
"""

#import the : numpy, pandas, and matplotlib libraries
import sklearn
#Importing pandas, numpy, and matplotlib libraries
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
#import the dataset, models, and evaluation metrics from sklearn :
"""
Import:
Logistic Regression from the sklearn.linear_model
Linear Support Vector Machines for classification from the sklearn.svm
Kneirest neighbors classfier from sklearn neighbors
Random Forest Classifier from sklearn.ensemble
train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV from sklearn.model_selection
confusion_matrix, classification_report, precision_score, recall_score, f1_score, plot_roc_curve from sklearn.metrics
load_breast_cancer from sklearn.datasets
"""
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV
from sklearn.metrics import roc_curve, auc
from sklearn.datasets import load_breast_cancer
# Turn the feature data into a dataframe
data = load_breast_cancer()
X_train = data.data
feature_names = data.feature_names

X_train_df = pd.DataFrame(X_train, columns=feature_names)

# Add the target columns, and fill it with the target data
X_train_df['target'] = data.target
# Show the dataframe
print(X_train_df)
# See the dataframe information
print(X_train_df.info())
#Divide data into train and test sets
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)
"""
this can be done in two steps:
step1:
Divide data into X (features) and y (target)

step2:
Divide data into test and training sets using train_test_split

"""
#Train the models imported
model1 = LogisticRegression()
model1.fit(X_train, y_train)

model2 = LinearSVC()
model2.fit(X_train, y_train)

model3 = KNeighborsClassifier()
model3.fit(X_train, y_train)

model4 = RandomForestClassifier()
model4.fit(X_train, y_train)

#Using metrics imported, show all results of trained models
y_pred1 = model1.predict(X_test)
accuracy1 = accuracy_score(y_test, y_pred1)
precision1 = precision_score(y_test, y_pred1, average='micro')
recall1 = recall_score(y_test, y_pred1, average='micro')
f1_score1 = f1_score(y_test, y_pred1, average='micro')

y_pred2 = model2.predict(X_test)
accuracy2 = accuracy_score(y_test, y_pred2)
precision2 = precision_score(y_test, y_pred2, average='micro')
recall2 = recall_score(y_test, y_pred2, average='micro')
f1_score2 = f1_score(y_test, y_pred2, average='micro')

y_pred3 = model3.predict(X_test)
accuracy3 = accuracy_score(y_test, y_pred3)
precision3 = precision_score(y_test, y_pred3, average='micro')
recall3 = recall_score(y_test, y_pred3, average='micro')
f1_score3 = f1_score(y_test, y_pred3, average='micro')

y_pred4 = model4.predict(X_test)
accuracy4 = accuracy_score(y_test, y_pred4)
precision4 = precision_score(y_test, y_pred4, average='micro')
recall4 = recall_score(y_test, y_pred4, average='micro')
f1_score4 = f1_score(y_test, y_pred4, average='micro')

print("Model 1 (Logistic Regression)")
print("Accuracy:", accuracy1)
print("Precision:", precision1)
print("Recall:", recall1)
print("F1 Score:", f1_score1)

print("Model 2 (Linear SVM)")
print("Accuracy:", accuracy2)
print("Precision:", precision2)
print("Recall:", recall2)
print("F1 Score:", f1_score2)

print("Model 3 (K Nearest Neighbors)")
print("Accuracy:", accuracy3)
print("Precision:", precision3)
print("Recall:", recall3)
print("F1 Score:", f1_score3)

print("Model 4 (Random Forest)")
print("Accuracy:", accuracy4)
print("Precision:", precision4)
print("Recall:", recall4)
print("F1 Score:", f1_score4)